{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239a076c-469c-4ffa-8c44-b229b246ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer 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\"}\n",
    "\n",
    "def query(payload, model_meta):\n",
    "    '''\n",
    "    Get the output from model_name\n",
    "    \n",
    "    Params:\n",
    "        payload: input data in json/dict format etc. {'inputs': 'question'}\n",
    "        model_meta: metadata object of the model\n",
    "        \n",
    "    Return:\n",
    "        response.json(): text output in dict\n",
    "    '''\n",
    "    \n",
    "    API_URL = model_meta.api_url\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5230d-8ff9-4a5d-9960-074ac7c1f82c",
   "metadata": {},
   "source": [
    "#### Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9794afe7-7fed-4876-b7dc-ae2c82ddb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_meta:\n",
    "    def __init__(self, model_name, api_url):\n",
    "        self.model_name = model_name\n",
    "        self.api_url = api_url\n",
    "        #self.model_type = model_type\n",
    "        #self.language = language\n",
    "        #self.version = version\n",
    "        #self.author = author\n",
    "    \n",
    "    def display_metadata(self):\n",
    "        print(\"Model Name:\", self.model_name)\n",
    "        print(\"Model API URL:\", self.api_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "990584cb-c7bb-419c-b280-1e7e585164fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flan_T5_small_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-small\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_large_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-large\")\n",
    "\n",
    "flan_T5_3b_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-xl\")\n",
    "\n",
    "flan_T5_11b_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-11b\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fb98c91-7e97-49b8-9400-56eab2644c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flan-t5-base'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flan_T5_base_meta.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3eba0-6b55-4342-9215-bcbda76ffdc1",
   "metadata": {},
   "source": [
    "#### Testing Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc283dd5-49d5-4048-9779-bded0d687e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'The model google/flan-t5-xl is too large to be loaded automatically (11GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
     ]
    }
   ],
   "source": [
    "output_flan_T5_3b = query({\n",
    "\t\"inputs\": \"The answer to the universe is\"},\n",
    "    flan_T5_3b_meta)\n",
    "\n",
    "print(output_flan_T5_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1bd73-1c9e-43c1-9d91-3847ec8bc9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6bf87-100b-4f40-89d0-8bacec8c2277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e742b-e923-42cc-8cf1-b1529679f76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe28d19-b16a-4c45-9f41-4f823250a795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d39fe7-6b4c-4500-a767-a460ba996a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Conda 2022.05) [python/3.9-2022.05]",
   "language": "python",
   "name": "python39_202205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
