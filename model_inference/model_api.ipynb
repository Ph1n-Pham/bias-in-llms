{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239a076c-469c-4ffa-8c44-b229b246ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer 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\"}\n",
    "\n",
    "def query(payload, model_meta):\n",
    "    '''\n",
    "    Get the output from model_name\n",
    "    \n",
    "    Params:\n",
    "        payload: input data in json/dict format etc. {'inputs': 'question'}\n",
    "        model_meta: metadata object of the model\n",
    "        \n",
    "    Return:\n",
    "        response.json(): text output in dict\n",
    "    '''\n",
    "    \n",
    "    API_URL = model_meta.api_url\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5230d-8ff9-4a5d-9960-074ac7c1f82c",
   "metadata": {},
   "source": [
    "#### Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9794afe7-7fed-4876-b7dc-ae2c82ddb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_meta:\n",
    "    def __init__(self, model_name, api_url):\n",
    "        self.model_name = model_name\n",
    "        self.api_url = api_url\n",
    "        #self.model_type = model_type\n",
    "        #self.version = version\n",
    "        #self.author = author\n",
    "        #self.dim = dim\n",
    "    \n",
    "    def display_metadata(self):\n",
    "        print(\"Model Name:\", self.model_name)\n",
    "        print(\"Model API URL:\", self.api_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990584cb-c7bb-419c-b280-1e7e585164fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flan_T5_small_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-small\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_large_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-large\")\n",
    "\n",
    "flan_T5_3b_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-xl\")\n",
    "\n",
    "flan_T5_11b_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-11b\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")\n",
    "\n",
    "flan_T5_base_meta = model_meta('flan-t5-base', \"https://api-inference.huggingface.co/models/google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb98c91-7e97-49b8-9400-56eab2644c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flan-t5-base'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flan_T5_base_meta.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3eba0-6b55-4342-9215-bcbda76ffdc1",
   "metadata": {},
   "source": [
    "#### Testing Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc283dd5-49d5-4048-9779-bded0d687e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'a symphony'}]\n"
     ]
    }
   ],
   "source": [
    "output_flan_T5_small = query({\n",
    "\t\"inputs\": \"The answer to the universe is\"},\n",
    "    flan_T5_small_meta)\n",
    "\n",
    "print(output_flan_T5_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b1bd73-1c9e-43c1-9d91-3847ec8bc9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a446b7b48f84067aefd03028416ffe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90eafa26b174368be532238ce9442e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a420ec9180ce485ab31cbf596a180b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4212505d1747159e1d2dba7b395fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3055fe57b371495587d478c18e0f2eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d885c26b8d14fbcaa650385080919f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fb8079db044927b363b771cbcf664c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PDNU0015/phamp1/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pour a cup of bolognese into a large bowl and add the pasta']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "inputs = tokenizer(\"A step by step recipe to make bolognese pasta:\", return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d6bf87-100b-4f40-89d0-8bacec8c2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 77.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 63.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 81.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 64.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /users/PDNU0015/phamp1/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/python/3.9-2022.05/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, safetensors, transformers\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/users/PDNU0015/phamp1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/users/PDNU0015/phamp1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed fsspec-2024.2.0 huggingface-hub-0.21.4 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e742b-e923-42cc-8cf1-b1529679f76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe28d19-b16a-4c45-9f41-4f823250a795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d39fe7-6b4c-4500-a767-a460ba996a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Conda 2022.05) [python/3.9-2022.05]",
   "language": "python",
   "name": "python39_202205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
